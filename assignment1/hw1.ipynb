{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "255.0\n",
      "29.54222\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import seaborn as sns\n",
    "\n",
    "batch_size_train = 1024\n",
    "batch_size_test = 10\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Lambda(lambda x : x*255)\n",
    "])\n",
    "# Define the loader for training data.\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('.', train=True, download=True,transform=transform),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "# Define the loader for testing data.\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('.', train=False, download=True, transform=transform),\n",
    "  batch_size=batch_size_test, shuffle=False)\n",
    "\n",
    "first_b = next(iter(test_loader))\n",
    "\n",
    "print(np.min(first_b[0].numpy()))\n",
    "print(np.max(first_b[0].numpy()))\n",
    "print(np.mean(first_b[0].numpy()))\n",
    "\n",
    "def KL_div_N01(z_mu, z_log_sigma_sq):\n",
    "    term_1 = z_log_sigma_sq.sum(axis=1)\n",
    "    term_2 = z_log_sigma_sq.exp().sum(axis=1)\n",
    "    term_3 = (z_mu * z_mu).sum(axis=1)\n",
    "    return 0.5 * (-term_1 + term_2 + term_3 - z_mu.shape[1]).mean()\n",
    "\n",
    "##\n",
    "## fully connected\n",
    "##\n",
    "class VAE( nn.Module ):\n",
    "    def __init__(self, n_input, n_output, n_z, n_layers, layer_size):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.enc = nn.ModuleList()\n",
    "        self.dec = nn.ModuleList()\n",
    "        self.n_z = n_z\n",
    "\n",
    "        for i in range(n_layers+1):\n",
    "            if i == 0: #first layers\n",
    "                self.enc.append(nn.Linear(n_input, layer_size))\n",
    "                self.dec.append(nn.Linear(n_z, layer_size))\n",
    "                self.enc.append(nn.ReLU())\n",
    "                self.dec.append(nn.ReLU())\n",
    "            elif i == n_layers: #last layers\n",
    "                self.enc.append(nn.Linear(layer_size, 2*n_z)) # we need this for enc's mu and sigma\n",
    "                self.dec.append(nn.Linear(layer_size, n_output))\n",
    "            else:\n",
    "                self.enc.append(nn.Linear(layer_size, layer_size))\n",
    "                self.dec.append(nn.Linear(layer_size, layer_size))\n",
    "                self.enc.append(nn.ReLU())\n",
    "                self.dec.append(nn.ReLU())\n",
    "\n",
    "        self.enc = nn.Sequential(*self.enc)\n",
    "        self.dec = nn.Sequential(*self.dec)\n",
    "  \n",
    "  \n",
    "    def enc_to_mean_lss(self,x):\n",
    "        enc_output = self.enc(x)\n",
    "        mean = enc_output[...,:self.n_z]\n",
    "        log_sigma_sq = enc_output[...,self.n_z:]\n",
    "        return mean, log_sigma_sq\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, log_sigma_sq = self.enc_to_mean_lss(x)\n",
    "\n",
    "        sigma = log_sigma_sq.exp().sqrt()\n",
    "        z = mean + torch.randn_like(mean)*sigma\n",
    "        output = self.dec(z)\n",
    "\n",
    "        return output\n",
    "  \n",
    "    def forward_train(self, x):\n",
    "\n",
    "        mean, log_sigma_sq = self.enc_to_mean_lss(x)\n",
    "        z = mean + torch.randn_like(mean) * (log_sigma_sq.exp().sqrt())\n",
    "        output = self.dec(z)\n",
    "\n",
    "        return output, mean, log_sigma_sq\n",
    "  \n",
    "    def encode_mean(self,x):\n",
    "        mean, log_sigma_sq = self.enc_to_mean_lss(x)\n",
    "        return mean\n",
    "\n",
    "    def encode(self,x):\n",
    "        mean, log_sigma_sq = self.enc_to_mean_lss(x)\n",
    "        sigma = self.enc_log_sigma_sq.exp().sqrt()\n",
    "        return mean + torch.randn_like(mean)*sigma\n",
    "\n",
    "    def decode(self,z):\n",
    "        return self.dec(z)\n",
    "\n",
    "class ConditionalVAE(VAE):\n",
    "    def __init__(self, n_input, n_output, n_z, n_layers, layer_size, n_condition):\n",
    "        super(ConditionalVAE, self).__init__(n_input, n_output, n_z, n_layers, layer_size)\n",
    "        \n",
    "        self.n_condition = n_condition\n",
    "        self.label_embedding = nn.Embedding(n_condition, n_condition)\n",
    "\n",
    "        # Modify enc and dec to accept condition\n",
    "        self.enc[0] = nn.Linear(n_input + n_condition, layer_size)\n",
    "        self.dec[0] = nn.Linear(n_z + n_condition, layer_size)\n",
    "    \n",
    "    def forward_train(self, x, condition):\n",
    "        condition = self.label_embedding(condition)\n",
    "        \n",
    "        x_conditioned = torch.cat([x, condition], dim=1)\n",
    "        mean, log_sigma_sq = self.enc_to_mean_lss(x_conditioned)\n",
    "\n",
    "        \n",
    "        z = mean + torch.randn_like(mean) * (log_sigma_sq.exp().sqrt())\n",
    "        \n",
    "        z_conditioned = torch.cat([z, condition], dim=1)\n",
    "        output = self.dec(z_conditioned)\n",
    "        \n",
    "        return output, mean, log_sigma_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics_vae = {'loss': [], 'kl_loss': [], 'mse_loss': []}\n",
    "performance_metrics_cvae = {'loss': [], 'kl_loss': [], 'mse_loss': []}\n",
    "## network params\n",
    "input_size = 28**2\n",
    "n_z = 2\n",
    "n_layers = 3\n",
    "layer_size = 512\n",
    "\n",
    "saved_params_path=\"saved_params\"\n",
    "pathlib.Path(f\"./{saved_params_path}/\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "## training params\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_instance = VAE(n_input=input_size, n_output=input_size, n_z=n_z, n_layers=n_layers, layer_size=layer_size)\n",
    "optimizer = torch.optim.Adam(vae_instance.parameters(), lr=3e-4)\n",
    "mse_loss_func = torch.nn.MSELoss()\n",
    "kl_loss_func = KL_div_N01\n",
    "\n",
    "cvae_instance = ConditionalVAE(n_input=input_size, n_output=input_size, n_z=n_z, n_layers=n_layers, layer_size=layer_size, n_condition=10)\n",
    "optimizer_cvae = torch.optim.Adam(cvae_instance.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (enc): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=4, bias=True)\n",
      "  )\n",
      "  (dec): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=784, bias=True)\n",
      "  )\n",
      ")\n",
      "[1,    59] loss: 5.133882 KL loss: 0.152716 MSE loss: 4.981166\n",
      "[2,    59] loss: 4.084414 KL loss: 0.023804 MSE loss: 4.060610\n",
      "[3,    59] loss: 4.075599 KL loss: 0.016323 MSE loss: 4.059276\n",
      "[4,    59] loss: 4.070745 KL loss: 0.012709 MSE loss: 4.058037\n",
      "[5,    59] loss: 3.899183 KL loss: 0.024054 MSE loss: 3.875129\n",
      "[6,    59] loss: 3.621896 KL loss: 0.021821 MSE loss: 3.600075\n",
      "[7,    59] loss: 3.527479 KL loss: 0.018977 MSE loss: 3.508501\n",
      "[8,    59] loss: 3.439088 KL loss: 0.019299 MSE loss: 3.419789\n",
      "[9,    59] loss: 3.324371 KL loss: 0.020581 MSE loss: 3.303790\n",
      "[10,    59] loss: 3.265940 KL loss: 0.020016 MSE loss: 3.245924\n",
      "Finished Training for VAE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "vae_instance = VAE(n_input=input_size, n_output=input_size, n_z=n_z, n_layers=n_layers, layer_size=layer_size)\n",
    "\n",
    "# Define the loss function.\n",
    "mse_loss_func = torch.nn.MSELoss()\n",
    "kl_loss_func = KL_div_N01\n",
    "\n",
    "# Define the optimizer.\n",
    "optimizer = torch.optim.Adam(vae_instance.parameters(), lr=3e-4)\n",
    "\n",
    "print(vae_instance)\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_kl_loss = 0.0\n",
    "    running_mse_loss = 0.0\n",
    "    running_n = 0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "        \n",
    "        images_in = inputs.view(inputs.shape[0], -1).clone().detach()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        x_hat, mean, log_sigma_sq  = vae_instance.forward_train(images_in)\n",
    "        \n",
    "        mse_loss = mse_loss_func(x_hat, images_in)\n",
    "        kl_div_loss = kl_loss_func(mean, log_sigma_sq)\n",
    "        loss = mse_loss + kl_div_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        running_kl_loss += kl_div_loss.item()\n",
    "        running_mse_loss += mse_loss.item()\n",
    "        running_n += inputs.shape[0]\n",
    "\n",
    "    print(\n",
    "        f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / running_n:.6f}',\n",
    "        f'KL loss: {running_kl_loss / running_n:.6f}',\n",
    "        f'MSE loss: {running_mse_loss / running_n:.6f}')\n",
    "\n",
    "    performance_metrics_vae['loss'].append(running_loss / running_n)\n",
    "    performance_metrics_vae['kl_loss'].append(running_kl_loss / running_n)\n",
    "    performance_metrics_vae['mse_loss'].append(running_mse_loss / running_n)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_kl_loss = 0.0\n",
    "    running_mse_loss = 0.0\n",
    "    running_n = 0\n",
    "    \n",
    "    torch.save(vae_instance.state_dict(), f'{saved_params_path}/{epoch}.pth')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(vae_instance.state_dict(), 'final_model.pth')\n",
    "# Save the optimization states. This is helpful for continual training.\n",
    "torch.save(optimizer.state_dict(), 'optimizer.pth')\n",
    "\n",
    "print('Finished Training for VAE')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Conditional VAE\n",
    "cvae_instance = ConditionalVAE(n_input=input_size, n_output=input_size, n_z=n_z, n_layers=n_layers, layer_size=layer_size, n_condition=10)\n",
    "optimizer_cvae = torch.optim.Adam(cvae_instance.parameters(), lr=3e-4)\n",
    "\n",
    "# Training loop for CVAE\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_kl_loss = 0.0\n",
    "    running_mse_loss = 0.0\n",
    "    running_n = 0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        images_in = inputs.view(inputs.shape[0], -1).clone().detach()\n",
    "\n",
    "        optimizer_cvae.zero_grad()\n",
    "\n",
    "        x_hat, mean, log_sigma_sq = cvae_instance.forward_train(images_in, labels)\n",
    "        \n",
    "        mse_loss = mse_loss_func(x_hat, images_in)\n",
    "        kl_div_loss = kl_loss_func(mean, log_sigma_sq)\n",
    "        loss = mse_loss + kl_div_loss\n",
    "        loss.backward()\n",
    "        optimizer_cvae.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_kl_loss += kl_div_loss.item()\n",
    "        running_mse_loss += mse_loss.item()\n",
    "        running_n += inputs.shape[0]\n",
    "        \n",
    "    print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / running_n:.6f}',\n",
    "          f'KL loss: {running_kl_loss / running_n:.6f}',\n",
    "          f'MSE loss: {running_mse_loss / running_n:.6f}')\n",
    "    \n",
    "    performance_metrics_cvae['loss'].append(running_loss / running_n)\n",
    "    performance_metrics_cvae['kl_loss'].append(running_kl_loss / running_n)\n",
    "    performance_metrics_cvae['mse_loss'].append(running_mse_loss / running_n)\n",
    "    \n",
    "    torch.save(cvae_instance.state_dict(), f'{saved_params_path}/cvae_{epoch}.pth')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(cvae_instance.state_dict(), 'final_model_cvae.pth')\n",
    "# Save the optimization states. This is helpful for continual training.\n",
    "torch.save(optimizer_cvae.state_dict(), 'optimizer_cvae.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "vae_instance.load_state_dict(torch.load('final_model.pth'))\n",
    "cvae_instance.load_state_dict(torch.load('final_model_cvae.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(1, n_epochs + 1))\n",
    "for metric in ['loss', 'kl_loss', 'mse_loss']:\n",
    "    plt.figure()\n",
    "    plt.title(f'{metric} over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric)\n",
    "    plt.plot(epochs, performance_metrics_vae[metric], label='VAE')\n",
    "    plt.plot(epochs, performance_metrics_cvae[metric], label='CVAE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space(model, dataloader, conditional=False):\n",
    "    latent_vars = []\n",
    "    labels = []\n",
    "    for i, data in enumerate(dataloader):\n",
    "        x, y = data\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        if conditional:\n",
    "            mean, _ = model.enc_to_mean_lss(torch.cat([x, model.label_embedding(y)], dim=1))\n",
    "        else:\n",
    "            mean, _ = model.enc_to_mean_lss(x)\n",
    "        latent_vars.append(mean.detach().numpy())\n",
    "        labels.append(y.detach().numpy())\n",
    "\n",
    "    latent_vars = np.concatenate(latent_vars, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(x=latent_vars[:, 0], y=latent_vars[:, 1], hue=labels, palette='tab10', legend='full')\n",
    "    plt.title(f\"{type(model).__name__} Latent Space\")\n",
    "    plt.show()\n",
    "\n",
    "# Assuming test_loader is your MNIST test set dataloader\n",
    "plot_latent_space(vae_instance, test_loader)\n",
    "plot_latent_space(cvae_instance, test_loader, conditional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add decode method to your ConditionalVAE class\n",
    "def decode(self, z, condition):\n",
    "    condition = self.label_embedding(condition)\n",
    "    z_conditioned = torch.cat([z, condition], dim=1)\n",
    "    return self.dec(z_conditioned)\n",
    "\n",
    "# Update ConditionalVAE with new method\n",
    "ConditionalVAE.decode = decode\n",
    "\n",
    "# Load the first 10 data points from test_loader\n",
    "first_10_data_points, first_10_labels = next(iter(DataLoader(test_loader.dataset, batch_size=10, shuffle=False)))\n",
    "\n",
    "# Reshape and encode the data points\n",
    "first_10_data_points = first_10_data_points.view(first_10_data_points.shape[0], -1)\n",
    "mean, _ = cvae_instance.enc_to_mean_lss(torch.cat([first_10_data_points, cvae_instance.label_embedding(first_10_labels)], dim=1))\n",
    "\n",
    "# Create a figure to plot 100 digits (10 rows of 10 digits each)\n",
    "fig, axes = plt.subplots(nrows=10, ncols=10, figsize=(10, 10))\n",
    "\n",
    "# Loop over each of the first 10 data points\n",
    "for i, latent_var in enumerate(mean):\n",
    "    # Loop over each class (0 to 9)\n",
    "    for j in range(10):\n",
    "        condition = torch.tensor([j])\n",
    "        # Decode and reshape the image\n",
    "        decoded_image = cvae_instance.decode(latent_var.unsqueeze(0), condition).detach().numpy().reshape(28, 28)\n",
    "        axes[i, j].imshow(decoded_image, cmap='gray')\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a batch of test data\n",
    "test_batch = next(iter(test_loader))\n",
    "test_images, _ = test_batch\n",
    "test_images = test_images.view(test_images.shape[0], -1)\n",
    "\n",
    "# Get z0 and x1\n",
    "with torch.no_grad():\n",
    "    z0 = vae_instance.encode_mean(test_images)\n",
    "    x1 = vae_instance.decode(z0)\n",
    "\n",
    "# Get z1\n",
    "with torch.no_grad():\n",
    "    z1 = vae_instance.encode_mean(x1)\n",
    "\n",
    "# Calculate similarity\n",
    "mse_loss_func = torch.nn.MSELoss()\n",
    "similarity = mse_loss_func(z0, z1)\n",
    "print(f\"Similarity (MSE) between z0 and z1: {similarity.item()}\")\n",
    "\n",
    "# Optional: Visualize z0 and z1\n",
    "z0_np = z0.cpu().numpy()\n",
    "z1_np = z1.cpu().numpy()\n",
    "plt.figure()\n",
    "plt.scatter(z0_np[:, 0], z0_np[:, 1], c='r', label='z0')\n",
    "plt.scatter(z1_np[:, 0], z1_np[:, 1], c='b', label='z1')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs-8395",
   "language": "python",
   "name": "cs-8395"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
